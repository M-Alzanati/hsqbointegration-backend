name: Deploy to AWS CloudFormation

on:
  workflow_dispatch:
    inputs:
      AWS_REGION:
        description: "AWS Region (default: us-east-1)"
        required: false
        default: "us-east-1"
      CREATE_SECRETS:
        description: "Bootstrap SecretsManager secrets stack (true only for first-time)"
        required: false
        default: "false"
      STAGE_NAME:
        description: "API Gateway stage name (e.g., prod, dev)"
        required: false
        default: "prod"
      QBO_ENV:
        description: "QuickBooks environment (production|sandbox)"
        required: false
        default: "production"
      DOCDB_CLUSTER_IDENTIFIER:
        description: "Desired DocDB cluster identifier (used for existence check)"
        required: false
        default: "quickbooks-hubspot-cluster"

jobs:
  deploy:
    name: Deploy CloudFormation and Lambda
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ inputs.AWS_REGION }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm ci
        working-directory: src

      - name: Package Lambda
        run: npm run package-lambda
        working-directory: src

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy S3 bucket (bucket-only stack)
        run: >
          aws cloudformation deploy \
            --stack-name lambda-deployment-bucket \
            --template-file src/bucket-only.yaml \
            --capabilities CAPABILITY_NAMED_IAM

      - name: Deploy Secrets stack (optional bootstrap)
        if: ${{ inputs.CREATE_SECRETS == 'true' }}
        run: >
          aws cloudformation deploy \
            --stack-name hubspot-quickbooks-secrets \
            --template-file src/secrets-only.yaml \
            --capabilities CAPABILITY_NAMED_IAM

      - name: Set DocumentDB password secret value (optional)
        if: ${{ inputs.CREATE_SECRETS == 'true' }}
        env:
          DOCDB_PASSWORD: ${{ secrets.DOCDB_PASSWORD }}
        run: |
          if [ -n "$DOCDB_PASSWORD" ]; then
            aws secretsmanager put-secret-value \
              --secret-id docdb/password \
              --secret-string "{\"password\":\"$DOCDB_PASSWORD\"}"
          else
            echo "DOCDB_PASSWORD secret not set, skipping."
          fi

      - name: Get bucket name output
        id: get_bucket
        run: |
          BUCKET=$(aws cloudformation describe-stacks --stack-name lambda-deployment-bucket --query "Stacks[0].Outputs[?OutputKey=='LambdaDeploymentBucketName'].OutputValue" --output text)
          echo "bucket_name=$BUCKET" >> $GITHUB_OUTPUT

      - name: Upload Lambda zip to S3
        run: aws s3 cp src/hubspot-quickbooks-backend.zip s3://${{ steps.get_bucket.outputs.bucket_name }}/hubspot-quickbooks-backend.zip

      - name: Detect existing DocDB cluster
        id: detect_docdb
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_ID: ${{ inputs.DOCDB_CLUSTER_IDENTIFIER }}
        run: |
          set -euo pipefail
          DATA_STACK=hubspot-quickbooks-data
          STACK_EXISTS=false
          CURR_USE_EXISTING=""
          if aws cloudformation describe-stacks --stack-name "$DATA_STACK" >/dev/null 2>&1; then
            STACK_EXISTS=true
            # Read the current parameter value to keep behavior sticky and avoid flip-flopping
            CURR_USE_EXISTING=$(aws cloudformation describe-stacks --stack-name "$DATA_STACK" \
              --query "Stacks[0].Parameters[?ParameterKey=='UseExistingDocDBCluster'].ParameterValue" --output text | tr -d '\r') || true
          fi
          EXISTS=false
          if aws docdb describe-db-clusters --region "$AWS_REGION" --db-cluster-identifier "$CLUSTER_ID" >/tmp/docdb.json 2>/dev/null; then
            EXISTS=true
            ENDPOINT=$(jq -r '.DBClusters[0].Endpoint' /tmp/docdb.json)
            SG=$(jq -r '.DBClusters[0].VpcSecurityGroups[0].VpcSecurityGroupId' /tmp/docdb.json)
            MASTER=$(jq -r '.DBClusters[0].MasterUsername' /tmp/docdb.json)
            SUBNET_GRP=$(jq -r '.DBClusters[0].DBSubnetGroup' /tmp/docdb.json)
          fi
          echo "data_stack_exists=$STACK_EXISTS" >> $GITHUB_OUTPUT
          if [ -n "$CURR_USE_EXISTING" ] && [ "$CURR_USE_EXISTING" != "None" ]; then
            echo "current_use_existing=$CURR_USE_EXISTING" >> $GITHUB_OUTPUT
          fi
          echo "exists=$EXISTS" >> $GITHUB_OUTPUT
          echo "cluster_id=$CLUSTER_ID" >> $GITHUB_OUTPUT
          if [ "$EXISTS" = true ]; then
            echo "endpoint=$ENDPOINT" >> $GITHUB_OUTPUT
            echo "sg_id=$SG" >> $GITHUB_OUTPUT
            echo "master=$MASTER" >> $GITHUB_OUTPUT
            echo "subnet_group_name=$SUBNET_GRP" >> $GITHUB_OUTPUT
          fi

      - name: Detect network (from network stack or DocDB subnet group)
        id: detect_network
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          SUBNET_GRP: ${{ steps.detect_docdb.outputs.subnet_group_name }}
        run: |
          set -euo pipefail
          STACK=hubspot-quickbooks-network
          # Prefer reading from an existing network stack's outputs
          if aws cloudformation describe-stacks --stack-name "$STACK" >/dev/null 2>&1; then
            EXISTING_VPC_ID=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='VpcId'].OutputValue" --output text)
            EXISTING_SUBNET1=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1Id'].OutputValue" --output text)
            EXISTING_SUBNET2=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2Id'].OutputValue" --output text)
            if [ -n "${EXISTING_VPC_ID:-}" ]; then echo "existing_vpc_id=$EXISTING_VPC_ID" >> $GITHUB_OUTPUT; fi
            if [ -n "${EXISTING_SUBNET1:-}" ]; then echo "existing_subnet1_id=$EXISTING_SUBNET1" >> $GITHUB_OUTPUT; fi
            if [ -n "${EXISTING_SUBNET2:-}" ]; then echo "existing_subnet2_id=$EXISTING_SUBNET2" >> $GITHUB_OUTPUT; fi
            exit 0
          fi

          # Fallback: derive from DocDB subnet group if provided
          if [ -n "${SUBNET_GRP:-}" ] && [ "${SUBNET_GRP}" != "null" ]; then
            aws docdb describe-db-subnet-groups --region "$AWS_REGION" --db-subnet-group-name "$SUBNET_GRP" >/tmp/subnetgrp.json
            EXISTING_VPC_ID=$(jq -r '.DBSubnetGroups[0].VpcId' /tmp/subnetgrp.json)
            EXISTING_SUBNET1=$(jq -r '.DBSubnetGroups[0].Subnets | map(.SubnetIdentifier) | sort | .[0]' /tmp/subnetgrp.json)
            EXISTING_SUBNET2=$(jq -r '.DBSubnetGroups[0].Subnets | map(.SubnetIdentifier) | sort | .[1]' /tmp/subnetgrp.json)
            if [ -n "${EXISTING_VPC_ID:-}" ]; then echo "existing_vpc_id=$EXISTING_VPC_ID" >> $GITHUB_OUTPUT; fi
            if [ -n "${EXISTING_SUBNET1:-}" ]; then echo "existing_subnet1_id=$EXISTING_SUBNET1" >> $GITHUB_OUTPUT; fi
            if [ -n "${EXISTING_SUBNET2:-}" ]; then echo "existing_subnet2_id=$EXISTING_SUBNET2" >> $GITHUB_OUTPUT; fi
          fi

      - name: Deploy Network stack
        env:
          EXISTING_VPC_ID: ${{ steps.detect_network.outputs.existing_vpc_id }}
          EXISTING_SUBNET1: ${{ steps.detect_network.outputs.existing_subnet1_id }}
          EXISTING_SUBNET2: ${{ steps.detect_network.outputs.existing_subnet2_id }}
        run: |
          set -euo pipefail
          STACK=hubspot-quickbooks-network

          # If the network stack already exists and we plan to reuse an existing VPC,
          # skip deploy when the outputs match the detected existing VPC/subnets.
          if aws cloudformation describe-stacks --stack-name "$STACK" >/dev/null 2>&1; then
            if [ -n "${EXISTING_VPC_ID:-}" ] \
              && [ -n "${EXISTING_SUBNET1:-}" ] \
              && [ -n "${EXISTING_SUBNET2:-}" ]; then
              CURRENT_VPC=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='VpcId'].OutputValue" --output text)
              CURRENT_PRIV1=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1Id'].OutputValue" --output text)
              CURRENT_PRIV2=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2Id'].OutputValue" --output text)
              if [ "$CURRENT_VPC" = "$EXISTING_VPC_ID" ] && [ "$CURRENT_PRIV1" = "$EXISTING_SUBNET1" ] && [ "$CURRENT_PRIV2" = "$EXISTING_SUBNET2" ]; then
                echo "Network stack already aligned with existing VPC/subnets; skipping deploy."
                exit 0
              fi
            fi
          fi

          PARAMS=""
          if [ -n "${EXISTING_VPC_ID:-}" ] && [ -n "${EXISTING_SUBNET1:-}" ] && [ -n "${EXISTING_SUBNET2:-}" ]; then
            PARAMS="--parameter-overrides UseExistingVpc=true ExistingVpcId=${EXISTING_VPC_ID} ExistingPrivateSubnet1Id=${EXISTING_SUBNET1} ExistingPrivateSubnet2Id=${EXISTING_SUBNET2}"
          else
            PARAMS="--parameter-overrides UseExistingVpc=false"
          fi

          aws cloudformation deploy \
            --stack-name "$STACK" \
            --template-file src/network.yaml \
            --capabilities CAPABILITY_NAMED_IAM \
            --no-fail-on-empty-changeset \
            $PARAMS

      - name: Get Network Stack outputs
        id: get_network
        run: |
          set -euo pipefail
          STACK=hubspot-quickbooks-network
          VPC_ID=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='VpcId'].OutputValue" --output text)
          PRIV1=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet1Id'].OutputValue" --output text)
          PRIV2=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='PrivateSubnet2Id'].OutputValue" --output text)
          LAMBDA_SG=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='LambdaSecurityGroupId'].OutputValue" --output text)
          echo "vpc_id=$VPC_ID" >> $GITHUB_OUTPUT
          echo "private_subnet1_id=$PRIV1" >> $GITHUB_OUTPUT
          echo "private_subnet2_id=$PRIV2" >> $GITHUB_OUTPUT
          echo "lambda_sg_id=$LAMBDA_SG" >> $GITHUB_OUTPUT

      - name: Deploy Data stack (DocumentDB)
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          VPC_ID: ${{ steps.get_network.outputs.vpc_id }}
          PRIV1: ${{ steps.get_network.outputs.private_subnet1_id }}
          PRIV2: ${{ steps.get_network.outputs.private_subnet2_id }}
          LAMBDA_SG: ${{ steps.get_network.outputs.lambda_sg_id }}
          DOCDB_EXISTS: ${{ steps.detect_docdb.outputs.exists }}
          DATA_STACK_EXISTS: ${{ steps.detect_docdb.outputs.data_stack_exists }}
          CURRENT_USE_EXISTING: ${{ steps.detect_docdb.outputs.current_use_existing }}
          EXISTING_CLUSTER_ID: ${{ steps.detect_docdb.outputs.cluster_id }}
          EXISTING_ENDPOINT: ${{ steps.detect_docdb.outputs.endpoint }}
          EXISTING_SG: ${{ steps.detect_docdb.outputs.sg_id }}
        run: |
          set -euo pipefail
          PARAMS="VpcId=$VPC_ID PrivateSubnet1Id=$PRIV1 PrivateSubnet2Id=$PRIV2 LambdaSecurityGroupId=$LAMBDA_SG"
          # Decide whether to reuse an external DocDB cluster. If the data stack already exists,
          # keep the current UseExistingDocDBCluster value to avoid toggling conditions that delete resources.
          USE_EXISTING=""
          if [ "${DATA_STACK_EXISTS}" = "true" ] && [ -n "${CURRENT_USE_EXISTING:-}" ]; then
            USE_EXISTING="$CURRENT_USE_EXISTING"
          else
            if [ "${DOCDB_EXISTS}" = "true" ]; then
              USE_EXISTING="true"
            else
              USE_EXISTING="false"
            fi
          fi

          if [ "$USE_EXISTING" = "true" ]; then
            PARAMS="$PARAMS UseExistingDocDBCluster=true ExistingDocDBClusterIdentifier=$EXISTING_CLUSTER_ID ExistingDocDBClusterEndpoint=$EXISTING_ENDPOINT ExistingDocDBSecurityGroupId=$EXISTING_SG"
          else
            PARAMS="$PARAMS UseExistingDocDBCluster=false DocDBClusterIdentifier=${{ inputs.DOCDB_CLUSTER_IDENTIFIER }}"
          fi
          aws cloudformation deploy \
            --region "$AWS_REGION" \
            --stack-name hubspot-quickbooks-data \
            --template-file src/data.yaml \
            --capabilities CAPABILITY_NAMED_IAM \
            --no-fail-on-empty-changeset \
            --parameter-overrides $PARAMS

      - name: Get Data Stack outputs
        id: get_data
        run: |
          set -euo pipefail
          STACK=hubspot-quickbooks-data
          DOCDB_ENDPOINT=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='DocDBClusterEndpoint'].OutputValue" --output text)
          DOCDB_ID=$(aws cloudformation describe-stacks --stack-name "$STACK" --query "Stacks[0].Outputs[?OutputKey=='DocDBClusterIdentifierOut'].OutputValue" --output text)
          echo "docdb_endpoint=$DOCDB_ENDPOINT" >> $GITHUB_OUTPUT
          echo "docdb_cluster_id=$DOCDB_ID" >> $GITHUB_OUTPUT

      - name: Deploy App stack (Lambda + API)
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          BUCKET: ${{ steps.get_bucket.outputs.bucket_name }}
          PRIV1: ${{ steps.get_network.outputs.private_subnet1_id }}
          PRIV2: ${{ steps.get_network.outputs.private_subnet2_id }}
          LAMBDA_SG: ${{ steps.get_network.outputs.lambda_sg_id }}
          DOCDB_ENDPOINT: ${{ steps.get_data.outputs.docdb_endpoint }}
          DOCDB_ID: ${{ steps.get_data.outputs.docdb_cluster_id }}
          MASTER_USER: ${{ steps.detect_docdb.outputs.master }}
          STAGE: ${{ inputs.STAGE_NAME }}
          QBO_ENV: ${{ inputs.QBO_ENV }}
        run: |
          set -euo pipefail
          DOCDB_MASTER_USERNAME=${MASTER_USER:-hubspot_quickbooks_user}
          aws cloudformation deploy \
            --region "$AWS_REGION" \
            --stack-name hubspot-quickbooks-app \
            --template-file src/app.yaml \
            --capabilities CAPABILITY_NAMED_IAM \
            --parameter-overrides \
              LambdaDeploymentBucket=$BUCKET \
              LambdaS3Key=hubspot-quickbooks-backend.zip \
              PrivateSubnet1Id=$PRIV1 \
              PrivateSubnet2Id=$PRIV2 \
              LambdaSecurityGroupId=$LAMBDA_SG \
              DocDBClusterEndpoint=$DOCDB_ENDPOINT \
              DocDBClusterIdentifier=$DOCDB_ID \
              DocDBMasterUsername=$DOCDB_MASTER_USERNAME \
              StageName=$STAGE \
              QuickBooksEnvironment=$QBO_ENV
